---
title: "p8105_hw6_xs2330"
author: "Xiao Shi"
date: "November 15, 2018"
output: github_document
---
## Problem 1
Using tidyverse library for data cleaning and analysis, leaps for stepwise selection, and the rest for cross validation
```{r setup, warning= FALSE, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)
library(leaps)
library(mgcv)
```

**Data cleaning and tidying**
```{r, message = FALSE, warning= FALSE}
raw_homicide = read_csv("./homicide-data.csv") 
homicide = raw_homicide %>%
  mutate(city_state = str_c(city, state, sep = ", ")) %>%
  mutate(case_status = recode(disposition, "Closed without arrest" = "unsolved", 
                      "Open/No arrest" = "unsolved",
                      "Closed by arrest" = "solved")) %>%
  filter(city_state != "Dallas, TX" & city_state != "Phoenix, AZ" & city_state != "Kansas City, MO" & city_state != "Tulsa, AL") %>%
  mutate(race_general = ifelse(victim_race == "White", "white","non_white"),
         victim_age = as.numeric(victim_age),
         race_general = fct_relevel(as.factor(race_general),"white")) %>%
  janitor::clean_names()

```
Upon removing cities that do not have information that we need, and mutate variables such as `victim_age` and `victim_race`, the resulting dataset consists `r nrow(homicide)` rows by `r ncol(homicide)` columns.

**Fitting model for Baltimore, MD**

This is a logistic regression with resolved vs unresolved as the outcome and `victim_age`, `victim_sex` and `race_general` (as just defined) as predictors.
```{r}
balti_homicide = homicide %>%
  filter(city_state == "Baltimore, MD") %>%
  mutate(case_status = ifelse(case_status == "solved",1,0))

glm_case_status = glm(case_status ~ victim_age + victim_sex + race_general, data = balti_homicide, family = binomial())
output_glm_case_status = summary(glm_case_status)
save(output_glm_case_status,file = "./homicide_balti.rdata")
```

Tidy the results and compare the adjusted odds ratio for solving homicides comparing white victims to non-white victims keeping all other variables fixed in Baltimore, MD.
```{r}
glm_case_status %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate),
         OR_lower = exp(estimate - std.error * 1.96),
         OR_upper = exp(estimate + std.error * 1.96)) %>%
  select(term, OR, OR_lower, OR_upper, p.value) %>% 
  knitr::kable(digits = 3)
```

From the above table, we see that homicide cases among non-whites are much less likely to be solved compared to cases among white people. The adjusted odds ratio is 0.441 with a p-value of 0.0000027, indicating statistically significant difference at a 95% confidence level.

**Run through the same process for all cities**

First we build a function that give results to a `city_state`
```{r}
white_nonwhite_solved = function(city_input){
city_homicide = homicide %>%
  filter(city_state == city_input) %>%
  mutate(case_status = ifelse(case_status == "solved",1,0))

glm_case_status = glm(case_status ~ victim_age + victim_sex + race_general, data = city_homicide, family = binomial()) %>%
  broom::tidy() %>% 
  filter(term == "race_generalnon_white") %>%
  mutate(OR = exp(estimate),
         OR_lower = exp(estimate - std.error * 1.96),
         OR_upper = exp(estimate + std.error * 1.96)) %>%
  select(term, OR, OR_lower, OR_upper, p.value) %>% 
  print(knitr::kable(glm_case_status))
}
```

Next we loop every city_state using the map function
```{r, echo=TRUE, results='hide'}
output_allcities = purrr::map_df(.x = unique(homicide$city_state), white_nonwhite_solved) %>%
  mutate(term = str_c("non-white", unique(homicide$city_state), sep = " in ")) %>%
  select(term, OR, OR_lower, OR_upper) %>%
  print(knitr::kable(output_allcities))
```

To better show the results we see from the above resulting table where homicide cases among non-whites are much less likely to be solved compared to cases among white people in all the cities, we plot a graph below. The graph consists estimated adjusted odds ratios and its range in a decreasing order.

**Create a plot showing the above case solving results**
```{r}
output_allcities$city = unique(homicide$city_state)
ggplot(data = output_allcities, mapping = aes(x = reorder(city, -OR), y = OR, color = reorder(city, -OR))) +
  geom_point() +
  geom_errorbar(aes(ymin = OR_lower, ymax = OR_upper)) +
  geom_hline(yintercept = 1, alpha = 0.5) +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 80, hjust = 1)) +
  labs(
    title = "Adjusted OR for homicide resolvation among non-whites and whites by city",
    x = "City, State",
    y = "Adjusted Odds Ratio"
  )
```

From the graph, we see that 43/47 cities except `Tampa, FL`, `Birmingham, AL`, `Durham, NC` showed a higher aOR estimation of homicide solving rate in white victim comparing to non-whites. Whatsmore, although we don't the similar trend in the three cities mentioned above, these three have a larger confidence interval. This indicates a higher possibility of less precise estimation. The graph is in a descending order based on the estimation of aOR.


##Problem 2

**Clean and tidy data**
```{r, results=FALSE, message= FALSE, warning=FALSE}
bbweight_raw = read_csv("./birthweight.csv", col_types = "dddddddddddddddddddd") 
cor(bbweight_raw)
bbweight = bbweight_raw %>%
  mutate(babysex = as.factor(ifelse(babysex == 1, "Male", "Female")),
         malform = as.factor(ifelse(malform == 1, "present", "absent")),
         frace = as.factor(frace),
         mrace = as.factor(mrace))
missing_rate = 1-nrow(as.data.frame(complete.cases(bbweight)))/nrow(bbweight)
```

Based on some literature review and previous knowledge, I would like to include `babysex`, `bhead`, `blength`, `wtgain`, and `smoken` when I first look through the dataset. However, after checking for correlation, we know that `mrace` and `frace` are hightly correlated with a correlation of 0.83, thus we don't include these two in the same model to prevent multicollinearity. Same applies to `ppbmi` and `ppwt` and `delwt`. Next, I use stepwise selection to build a model statistically, and later use the previous literature review results to polish the model.

**fitting the full model**
```{r, echo=TRUE, results='hide'}
full_model = lm(bwt ~ .-frace -ppbmi -delwt, data = bbweight)
summary(full_model)
```

**Stepwise selection**
```{r, echo=TRUE, results='hide'}
step_model = step(full_model, direction = "both", trace = FALSE)
summary(step_model)
```

Now all the predictor variables in the model looks promising (based on their p-value not my lit review yet) including babysex, bhead, blength, fincome, gaweeks, mheight, mrace, parity, ppwt, smoken, wtgain. However, since we are not a statistics savage, we need to link some literature review results back to the model. Also, overfitting could be a problem with too much predictors. Since `babysex`, `bhead`, `blength`, `wtgain`, and `smoken` are all statistically significant variables in the stepwise model, I decide to use this model as my predicting model.



